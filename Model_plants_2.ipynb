{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JV3O5H8ikgh8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCF9q4F4k4Mg",
        "outputId": "32dc9a00-68b5-41ca-bd9b-5fa45d2c55c8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axyjRDIsmwUG",
        "outputId": "cb09be1c-62f2-4128-9c3d-ee7d977e8eb1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['Basale',\n",
        "               'Guava',\n",
        "               'Neem',\n",
        "               'Sandalwood',\n",
        "               'Tulsi']\n",
        "# class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "# nb_classes = len(class_names)\n",
        "\n",
        "# IMAGE_SIZE = (150, 150)"
      ],
      "metadata": {
        "id": "LlZH3G__vYhc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDataGen = ImageDataGenerator(rotation_range=5,\n",
        "                                  width_shift_range=0.1,\n",
        "                                  height_shift_range=0.1,\n",
        "                                  rescale=1.0 / 255,\n",
        "                                  shear_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=False,\n",
        "                                  fill_mode='nearest')\n",
        "\n",
        "testDataGen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "trainGenerator = trainDataGen.flow_from_directory(os.path.join('Dataset', 'Train'),\n",
        "                                                  target_size=(150, 150),\n",
        "                                                  batch_size=32,\n",
        "                                                  color_mode='rgb',\n",
        "                                                  classes=[str(Class)\n",
        "                                                           for Class in range(5)],\n",
        "                                                  class_mode='categorical')\n",
        "\n",
        "validationGenerator = testDataGen.flow_from_directory(os.path.join('Dataset', 'Validation'),\n",
        "                                                      target_size=(150, 150),\n",
        "                                                      batch_size=32,\n",
        "                                                      color_mode='rgb',\n",
        "                                                      classes=[\n",
        "                                                          str(Class) for Class in range(5)],\n",
        "                                                      class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXZqla24k3Dn",
        "outputId": "9905ae38-a2ae-4615-be80-c856d36b108c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 303 images belonging to 5 classes.\n",
            "Found 35 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), padding = 'same', activation = 'relu', kernel_initializer = 'he_uniform', input_shape = (150, 150, 3)))\n",
        "model.add(Conv2D(32, (5, 5), padding = 'same', activation = 'relu', kernel_initializer = 'he_uniform'))\n",
        "model.add(Conv2D(32, (5, 5), padding = 'same', activation = 'relu', kernel_initializer = 'he_uniform'))\n",
        "model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding = 'same', activation = 'relu', kernel_initializer = 'he_uniform'))\n",
        "model.add(Conv2D(64, (3, 3), padding = 'same', activation = 'relu', kernel_initializer = 'he_uniform'))\n",
        "model.add(Conv2D(64, (3, 3), padding = 'same', activation = 'relu', kernel_initializer = 'he_uniform'))\n",
        "model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(5, activation = 'softmax'))\n",
        "\n",
        "model.compile(optimizer = Adam(learning_rate = 1e-3, decay = 1e-5), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "id": "XSQNRl5HluXn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if not os.path.isdir('Model_2'):\n",
        "    os.mkdir('Model_2')\n",
        "\n",
        "callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                               patience=7, min_lr=1e-5),\n",
        "             EarlyStopping(monitor='val_loss', patience=9,  # Patience should be larger than the one in ReduceLROnPlateau\n",
        "                           min_delta=1e-5),\n",
        "             CSVLogger(os.path.join('Model_2', 'training.log'), append=True),\n",
        "             ModelCheckpoint(os.path.join(\n",
        "                 'Model_2', 'backup_last_model.hdf5')),\n",
        "             ModelCheckpoint(os.path.join('Model_2', 'best_val_acc.hdf5'),\n",
        "                             monitor='val_accuracy', mode='max', save_best_only=True),\n",
        "             ModelCheckpoint(os.path.join('Model_2', 'best_val_loss.hdf5'), monitor='val_loss', mode='min', save_best_only=True)]\n",
        "\n",
        "model.fit(trainGenerator, epochs=20,\n",
        "          validation_data=validationGenerator, callbacks=callbacks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NXVpy9Wl9Sb",
        "outputId": "f0c99e69-c434-4ae3-9d58-32b8ee6c32f6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "10/10 [==============================] - 127s 13s/step - loss: 11.2362 - accuracy: 0.2244 - val_loss: 1.7033 - val_accuracy: 0.3429 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 114s 11s/step - loss: 1.5311 - accuracy: 0.3663 - val_loss: 1.4301 - val_accuracy: 0.4286 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 115s 11s/step - loss: 1.4271 - accuracy: 0.3861 - val_loss: 1.0489 - val_accuracy: 0.6857 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 106s 11s/step - loss: 1.0955 - accuracy: 0.5017 - val_loss: 0.9562 - val_accuracy: 0.6571 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 113s 11s/step - loss: 0.9707 - accuracy: 0.6139 - val_loss: 0.6821 - val_accuracy: 0.7714 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 109s 11s/step - loss: 0.8175 - accuracy: 0.6898 - val_loss: 0.5401 - val_accuracy: 0.7429 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 108s 11s/step - loss: 0.7919 - accuracy: 0.6865 - val_loss: 0.5662 - val_accuracy: 0.7429 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 113s 11s/step - loss: 0.7824 - accuracy: 0.7129 - val_loss: 0.4547 - val_accuracy: 0.8286 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 108s 11s/step - loss: 0.5058 - accuracy: 0.8185 - val_loss: 0.4738 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 110s 11s/step - loss: 0.5895 - accuracy: 0.8086 - val_loss: 0.2567 - val_accuracy: 0.9714 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 108s 10s/step - loss: 0.6009 - accuracy: 0.7756 - val_loss: 0.2582 - val_accuracy: 0.8857 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 106s 11s/step - loss: 0.4714 - accuracy: 0.8251 - val_loss: 0.4977 - val_accuracy: 0.7429 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 104s 10s/step - loss: 0.4902 - accuracy: 0.8053 - val_loss: 0.3239 - val_accuracy: 0.9143 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 106s 10s/step - loss: 0.6204 - accuracy: 0.7822 - val_loss: 0.7996 - val_accuracy: 0.7143 - lr: 0.0010\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 106s 10s/step - loss: 0.4505 - accuracy: 0.8185 - val_loss: 0.2626 - val_accuracy: 0.9429 - lr: 0.0010\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 104s 10s/step - loss: 0.3793 - accuracy: 0.8878 - val_loss: 0.2720 - val_accuracy: 0.9143 - lr: 0.0010\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 107s 11s/step - loss: 0.6634 - accuracy: 0.7459 - val_loss: 0.6415 - val_accuracy: 0.6571 - lr: 0.0010\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 107s 11s/step - loss: 0.5737 - accuracy: 0.7921 - val_loss: 0.5762 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 106s 10s/step - loss: 0.5754 - accuracy: 0.7756 - val_loss: 0.4740 - val_accuracy: 0.8571 - lr: 1.0000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fba916f1dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(os.path.join('Model_2', 'best_val_loss.hdf5'))\n",
        "loss, acc = model.evaluate(validationGenerator)\n",
        "print('Loss on Validation Data : ', loss)\n",
        "print('Accuracy on Validation Data :', '{:.4%}'.format(acc))  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBs5gtmxl-Nk",
        "outputId": "1e656f90-4012-4743-9f3c-a4b222a5386c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 3s 211ms/step - loss: 0.2567 - accuracy: 0.9714\n",
            "Loss on Validation Data :  0.2566501498222351\n",
            "Accuracy on Validation Data : 97.1429%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import PIL.ImageOps as ImageOps\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "zDvrv0BZogHb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBvgaFK7r2HT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.ndarray(shape=(1, 150, 150, 3), dtype=np.float32)\n",
        "\n",
        "class_names = ['Basale',\n",
        "               'Guava',\n",
        "               'Neem',\n",
        "               'Sandalwood',\n",
        "               'Tulsi']\n",
        "image = Image.open('/content/gdrive/MyDrive/plant_dataset/Neem/AI-S-008.jpg')\n",
        "#image sizing\n",
        "# image = ImageOps.grayscale(image)\n",
        "\n",
        "size = (150, 150)\n",
        "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
        "\n",
        "#turn the image into a numpy array\n",
        "image_array = np.asarray(image)\n",
        "# np.reshape(image_array, newshape=(150, 150,3))\n",
        "# Normalize the image\n",
        "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
        "print(normalized_image_array.shape)\n",
        "# Load the image into the array\n",
        "data[0] = normalized_image_array\n",
        "\n",
        "# run the inference\n",
        "prediction = model.predict(data)\n",
        "pred_label = np.argmax(prediction, axis = 1) # We take the highest probability\n",
        "class_prediction = class_names[pred_label[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOI-ncjHoIhs",
        "outputId": "4981a9ac-6a91-43fd-a2d3-24f274bcca6f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 150, 3)\n",
            "1/1 [==============================] - 0s 265ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if class_prediction == 'Basale':\n",
        "    print('Basale: Basale has an anti-inflammatory activity and wound healing ability. It can be helpful as a first aid, and the leaves of this plant can be crushed and applied to burns, scalds and wounds to help in healing of the wounds.')\n",
        "if class_prediction == 'Guava':\n",
        "    print('Guava: Aside from bearing a delicious taste, the fruit of the Guava tree is a rich source of Vitamin C and antioxidants. It is especially effective against preventing infections such as Gastrointestinal infections, Respiratory infections, Oral/dental infections and Skin infections. It can also aid in the treatment of Hypertension, Fever, Pain, Liver and Kidney problems. ')\n",
        "if class_prediction == 'Neem':\n",
        "    print('Neem: Prevalent in traditional remedies from a long time, Neem is considered as a boon for Mankind. It helps to cure many skin diseases such as Acne, fungal infections, dandruff, leprosy, and also nourishes and detoxifies the skin. It also boosts your immunity and act as an Insect and Mosquito Repellent. It helps to reduce joint paint as well and prevents Gastrointestinal Diseases')\n",
        "if class_prediction == 'Sandalwood':\n",
        "    print('Sandalwood: Sandalwood is used for treating the common cold, cough, bronchitis, fever, and sore mouth and throat. It is also used to treat urinary tract infections (UTIs), liver disease, gallbladder problems, heatstroke, gonorrhea, headache, and conditions of the heart and blood vessels (cardiovascular disease).')\n",
        "if class_prediction == 'Tulsi':\n",
        "    print('Tulsi: Tulsi plant has the potential to cure a lot of ailments, and is used a lot in traditional remedies. Tulsi can help cure fever, to treat skin problems like acne, blackheads and premature ageing, to treat insect bites. Tulsi is also used to treat heart disease and fever, and respiratory problems.')\n"
      ],
      "metadata": {
        "id": "3n0XBqHAoVTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a810198e-f7e9-4547-a41c-03c9fc76b31c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neem: Prevalent in traditional remedies from a long time, Neem is considered as a boon for Mankind. It helps to cure many skin diseases such as Acne, fungal infections, dandruff, leprosy, and also nourishes and detoxifies the skin. It also boosts your immunity and act as an Insect and Mosquito Repellent. It helps to reduce joint paint as well and prevents Gastrointestinal Diseases\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ydkK3b0C--Fi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}